# HÆ°á»›ng Dáº«n TÃ­ch Há»£p AI ÄÆ¡n Giáº£n ğŸ¤–

## ğŸ“‹ Tá»•ng Quan Há»‡ Thá»‘ng

Há»‡ thá»‘ng Ä‘Ã£ Ä‘Æ°á»£c Ä‘Æ¡n giáº£n hÃ³a vá»›i:

### ğŸ¯ 3 Tráº¡ng ThÃ¡i Camera
1. **Äang khá»Ÿi Ä‘á»™ng** (starting) - ğŸŸ  MÃ u cam  
2. **Äang hoáº¡t Ä‘á»™ng** (active) - ğŸŸ¢ MÃ u xanh lÃ¡  
3. **Lá»—i** (error) - ğŸ”´ MÃ u Ä‘á»  

### ğŸ“„ JSON Response Format
AI model sáº½ tráº£ vá» JSON vá»›i format:
```json
{
  "box": [x, y, width, height],  // Tá»a Ä‘á»™ bounding box (array of int)
  "confident": 85,               // XÃ¡c suáº¥t lÃ  con ngÆ°á»i (int 0-100)
  "controll": "follow"           // Lá»‡nh Ä‘iá»u khiá»ƒn robot (string)
}
```

## ğŸ”§ CÃ¡ch TÃ­ch Há»£p

### BÆ°á»›c 1: Cáº­p Nháº­t AI Service

Trong file `lib/services/ai_model_service.dart`, thay tháº¿ hÃ m `_runModelInference()`:

```dart
Future<Map<String, dynamic>> _runModelInference(CameraImage cameraImage) async {
  try {
    // TODO: Gá»i mÃ´ hÃ¬nh AI thá»±c táº¿ cá»§a báº¡n á»Ÿ Ä‘Ã¢y
    
    // VÃ­ dá»¥:
    // 1. Preprocess camera image
    final imageData = preprocessImage(cameraImage);
    
    // 2. Run inference
    final result = await yourModelInference(imageData);
    
    // 3. Parse káº¿t quáº£ vÃ  táº¡o JSON response
    return {
      "box": result.boundingBox,        // [x, y, width, height]
      "confident": result.confidence,   // 0-100
      "controll": result.command        // "follow", "search", "stop"
    };
    
  } catch (e) {
    debugPrint("Lá»—i inference: $e");
    return {
      "box": [],
      "confident": 0,
      "controll": "stop"
    };
  }
}
```

### BÆ°á»›c 2: Sá»­ dá»¥ng Real Camera Stream

Trong file `follow_human_screen.dart`, thay tháº¿ simulation báº±ng real camera stream:

```dart
void _startHumanDetection() {
  if (!_aiService.isModelLoaded || _cameraController == null) {
    return;
  }
  
  // Sá»­ dá»¥ng camera stream thay vÃ¬ timer
  _cameraController!.startImageStream((CameraImage image) async {
    if (!_isProcessing && _isFollowing) {
      _isProcessing = true;
      
      try {
        // Gá»i AI service thá»±c táº¿
        final result = await _aiService.processFrame(image);
        
        if (result != null && mounted) {
          _handleAIResult(result);
        }
      } catch (e) {
        debugPrint("Lá»—i xá»­ lÃ½ frame: $e");
      } finally {
        _isProcessing = false;
      }
    }
  });
}

void _stopHumanDetection() {
  _cameraController?.stopImageStream();
  setState(() {
    _humanBoundingBox = null;
    _currentCommand = "stop";
    _confidence = 0;
  });
  _pulseController.stop();
}
```

## ğŸ“Š CÃ¡c Lá»‡nh Äiá»u Khiá»ƒn Robot

### "follow"
- Robot theo dÃµi ngÆ°á»i Ä‘Æ°á»£c phÃ¡t hiá»‡n
- Hiá»ƒn thá»‹ bounding box vá»›i confidence
- UI: Xanh lÃ¡, pulse animation

### "search"  
- Robot tÃ¬m kiáº¿m ngÆ°á»i
- KhÃ´ng cÃ³ bounding box
- UI: Info overlay hiá»ƒn thá»‹ "searching"

### "stop"
- Robot dá»«ng hoáº¡t Ä‘á»™ng
- XÃ³a táº¥t cáº£ UI elements
- Tráº¡ng thÃ¡i idle

## ğŸ¨ UI Components

### Status Indicator (gÃ³c trÃªn pháº£i)
```dart
StatusIndicator(
  message: _cameraStatus.message,    // "Äang khá»Ÿi Ä‘á»™ng", "Hoáº¡t Ä‘á»™ng", "Lá»—i"
  color: _cameraStatus.color,        // Colors.orange, Colors.green, Colors.red
  icon: _cameraStatus.icon,          // Icons.hourglass_empty, Icons.videocam, Icons.error
  isAnimated: _cameraStatus == CameraStatus.starting,
)
```

### Bounding Box
- Chá»‰ hiá»ƒn thá»‹ khi cÃ³ detection (box khÃ´ng rá»—ng)
- Pulse animation khi active
- Label hiá»ƒn thá»‹ "Human X%" vá»›i confidence

### Info Overlay
- Hiá»ƒn thá»‹ command hiá»‡n táº¡i
- Hiá»ƒn thá»‹ confidence khi cÃ³ detection
- á» gÃ³c trÃªn trÃ¡i, chá»‰ khi Ä‘ang follow

## ğŸš€ VÃ­ Dá»¥ Implementation

### Vá»›i TensorFlow Lite
```dart
Future<Map<String, dynamic>> _runModelInference(CameraImage cameraImage) async {
  // Convert CameraImage to input tensor
  final input = await convertCameraImageToTensor(cameraImage);
  
  // Run inference
  final output = await _interpreter.run(input);
  
  // Parse output
  final detections = parseDetections(output);
  
  if (detections.isNotEmpty) {
    final bestDetection = detections.first;
    return {
      "box": [
        bestDetection.x,
        bestDetection.y, 
        bestDetection.width,
        bestDetection.height
      ],
      "confident": (bestDetection.confidence * 100).toInt(),
      "controll": bestDetection.confidence > 0.7 ? "follow" : "search"
    };
  }
  
  return {
    "box": [],
    "confident": 0,
    "controll": "search"
  };
}
```

### Vá»›i Custom HTTP API
```dart
Future<Map<String, dynamic>> _runModelInference(CameraImage cameraImage) async {
  // Convert image to base64
  final base64Image = await convertImageToBase64(cameraImage);
  
  // Send to API
  final response = await http.post(
    Uri.parse('https://your-api.com/detect'),
    body: json.encode({'image': base64Image}),
    headers: {'Content-Type': 'application/json'},
  );
  
  // Parse response
  final result = json.decode(response.body);
  
  return {
    "box": result['bounding_box'] ?? [],
    "confident": result['confidence'] ?? 0,
    "controll": result['action'] ?? 'stop'
  };
}
```

## ğŸ”„ Test Flow

1. **Khá»Ÿi Ä‘á»™ng app** â†’ Status: "Äang khá»Ÿi Ä‘á»™ng" (cam)
2. **AI model load xong** â†’ Status: "Hoáº¡t Ä‘á»™ng" (xanh)  
3. **Nháº¥n "Follow"** â†’ Báº¯t Ä‘áº§u xá»­ lÃ½ frames
4. **PhÃ¡t hiá»‡n ngÆ°á»i** â†’ Hiá»ƒn thá»‹ bounding box + "follow" command
5. **Máº¥t tÃ­ch ngÆ°á»i** â†’ XÃ³a bounding box + "search" command
6. **Nháº¥n "Stop"** â†’ Dá»«ng táº¥t cáº£ + "stop" command

## âš¡ Performance Tips

1. **Frame Rate**: Xá»­ lÃ½ má»—i 500ms thay vÃ¬ real-time
2. **Resolution**: Sá»­ dá»¥ng medium resolution cho camera
3. **Model Size**: Giá»¯ model < 10MB 
4. **Inference Time**: Má»¥c tiÃªu < 100ms per frame
5. **Error Handling**: LuÃ´n cÃ³ fallback response

## ğŸ¯ Káº¿t Quáº£

âœ… Giao diá»‡n Ä‘Æ¡n giáº£n, dá»… hiá»ƒu  
âœ… 3 tráº¡ng thÃ¡i camera rÃµ rÃ ng  
âœ… JSON format chuáº©n cho AI  
âœ… Real-time bounding box display  
âœ… Robot command integration ready  
âœ… Error handling robust  

Há»‡ thá»‘ng giá» Ä‘Ã¢y Ä‘Æ¡n giáº£n vÃ  dá»… tÃ­ch há»£p! ğŸš€ 